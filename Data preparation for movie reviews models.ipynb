{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "- Loading text data\n",
    "- Cleaning text\n",
    "- Extract total vocabulary\n",
    "- Adapt the reviews to match the vocabulary\n",
    "- combine the adpated reviews for positive reviews\n",
    "- combine the adpated reviews for negative reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "# load the text from a file\n",
    "def load_text_file(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        text = file.read()\n",
    "    return text\n",
    "\n",
    "def load_text_file_dir(dirname):\n",
    "    for filename in listdir(dirname):\n",
    "        \n",
    "        if not filename.endswith(\".txt\"):\n",
    "            next\n",
    "        text = load_text_file(dirname+'//'+filename)\n",
    "        #print(filename)\n",
    "        #print(text)\n",
    "        \n",
    "dirname = r'C:\\Users\\Pureti\\Documents\\PythonDB\\Machine Learning\\nlp\\movie reviews data\\movie_reviews\\txt_data\\neg'\n",
    "filename = 'cv000_29416.txt' \n",
    "load_text_file_dir(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text cleaning\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    # split into words by white space\n",
    "    words = text.split()\n",
    "    \n",
    "    # prepare regex for char filtering\n",
    "    re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "\n",
    "    # remove punctuation from each word\n",
    "    words = [re_punc.sub('', word) for word in words]\n",
    "\n",
    "    # remove remaining words that are not alphabetic\n",
    "    words = [word for word in words if word.isalpha()]\n",
    "\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    \n",
    "    # filter out short words\n",
    "    words = [word for word in words if len(word) > 1]\n",
    "    return words\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plot', 'two', 'teen', 'couples', 'go', 'church', 'party', 'drink', 'drive', 'get', 'accident', 'one', 'guys', 'dies', 'girlfriend', 'continues', 'see', 'life', 'nightmares', 'whats', 'deal', 'watch', 'movie', 'sorta', 'find', 'critique', 'mindfuck', 'movie', 'teen', 'generation', 'touches', 'cool', 'idea', 'presents', 'bad', 'package', 'makes', 'review', 'even', 'harder', 'one', 'write', 'since', 'generally', 'applaud', 'films', 'attempt', 'break', 'mold', 'mess', 'head', 'lost', 'highway', 'memento', 'good', 'bad', 'ways', 'making', 'types', 'films', 'folks', 'didnt', 'snag', 'one', 'correctly', 'seem', 'taken', 'pretty', 'neat', 'concept', 'executed', 'terribly', 'problems', 'movie', 'well', 'main', 'problem', 'simply', 'jumbled', 'starts', 'normal', 'downshifts', 'fantasy', 'world', 'audience', 'member', 'idea', 'whats', 'going', 'dreams', 'characters', 'coming', 'back', 'dead', 'others', 'look', 'like', 'dead', 'strange', 'apparitions']\n"
     ]
    }
   ],
   "source": [
    "# test the functions\n",
    "text = load_text_file(dirname+'//'+filename)\n",
    "\n",
    "words = clean_text(text)\n",
    "print(words[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# Collect the vocabulary for all the files\n",
    "def add_file_to_vocab_dict(filename, vdict):\n",
    "    text = load_text_file(filename)\n",
    "    words = clean_text(text)\n",
    "    vdict.update(words)\n",
    "\n",
    "def collect_vocab_from_all_files(dirname, vdict):\n",
    "    for filename in listdir(dirname):\n",
    "        if not filename.endswith(\".txt\"):\n",
    "            next\n",
    "        add_file_to_vocab_dict(dirname+'\\\\'+filename, vdict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33008\n"
     ]
    }
   ],
   "source": [
    "# vocab dictionary\n",
    "vdict = Counter()\n",
    "dirname1 = r'C:\\Users\\Pureti\\Documents\\PythonDB\\Machine Learning\\nlp\\movie reviews data\\movie_reviews\\txt_data\\neg'\n",
    "dirname2 = r'C:\\Users\\Pureti\\Documents\\PythonDB\\Machine Learning\\nlp\\movie reviews data\\movie_reviews\\txt_data\\pos'\n",
    "\n",
    "collect_vocab_from_all_files(dirname, vdict)\n",
    "collect_vocab_from_all_files(dirname, vdict)\n",
    "print(len(vdict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The words that only appear once across all reviews are not predictive.\n",
    "- The words that appear most across all reviews are not useful too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13374\n"
     ]
    }
   ],
   "source": [
    "min_occurane = 5\n",
    "words = [w for w,c in vdict.items() if c >= min_occurane]\n",
    "print(len(words))\n",
    "\n",
    "# save vocab list into a file\n",
    "total_vocab = '\\n'.join(words)\n",
    "dirname3 = r'C:\\Users\\Pureti\\Documents\\PythonDB\\Machine Learning\\nlp\\movie reviews data\\movie_reviews\\txt_data'\n",
    "with open(dirname3+'\\\\'+'vocab_list.txt', 'w') as file:\n",
    "    file.write(total_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rewrite the reviews by comparing them with the vocab\n",
    "# and save the newly written reviews\n",
    "\n",
    "def file_to_line_based_on_vocab(filename, vocab):\n",
    "    text = load_text_file(filename)\n",
    "    words = clean_text(text)\n",
    "    words = [word for word in words if word in vocab]\n",
    "    return ''.join(words)\n",
    "\n",
    "def process_all_files_based_on_vocab(dirname, vocab):\n",
    "    lines = list()\n",
    "\n",
    "    for filename in listdir(dirname):\n",
    "        if not filename.endswith(\".txt\"):\n",
    "            next\n",
    "        path = dirname+'\\\\'+filename\n",
    "        line = file_to_line_based_on_vocab(path, vocab)\n",
    "        lines.append(line)\n",
    "    return lines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_filename = 'vocab_list.txt'\n",
    "vocab = load_text_file(dirname3+'\\\\'+vocab_filename)\n",
    "vocab = vocab.split()\n",
    "vocab = set(vocab)\n",
    "\n",
    "# prepare negative reviews\n",
    "neg_lines = process_all_files_based_on_vocab(dirname1, vocab)\n",
    "data = '\\n'.join(neg_lines)\n",
    "with open(dirname1+'\\\\'+'negative.txt', 'w') as file:\n",
    "    file.write(data)\n",
    "\n",
    "\n",
    "# prepare positive reviews\n",
    "pos_lines = process_all_files_based_on_vocab(dirname2, vocab)\n",
    "data = '\\n'.join(pos_lines)\n",
    "with open(dirname2+'\\\\'+'positive.txt', 'w') as file:\n",
    "    file.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end\n",
    "- positive reviews that are adapted to vocabulary are combined and stored into positive.txt file\n",
    "- negative reviews that are adapted to vocabulary are combined and stored into negative.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
